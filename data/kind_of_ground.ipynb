{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 14:30:44.046048: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-11 14:30:44.134700: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-11 14:30:44.137758: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-03-11 14:30:44.137770: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-03-11 14:30:44.646950: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-11 14:30:44.647005: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-11 14:30:44.647011: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27000 files belonging to 10 classes.\n",
      "Using 21600 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 14:30:46.343763: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-11 14:30:46.343892: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-03-11 14:30:46.343923: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-03-11 14:30:46.343953: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-03-11 14:30:46.343971: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-03-11 14:30:46.343989: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-03-11 14:30:46.344006: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-03-11 14:30:46.344024: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-03-11 14:30:46.344042: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-03-11 14:30:46.344045: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-03-11 14:30:46.344248: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"./EuroSAT_RGB\"\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(64, 64),\n",
    "  batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27000 files belonging to 10 classes.\n",
      "Using 5400 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(64, 64),\n",
    "  batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64, 3)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/louis/python_environments/renault_env/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "cropper_layer = tf.keras.layers.Cropping2D(cropping=((16, 16)))\n",
    "\n",
    "cropped_ds = train_ds.map(lambda x, y: (cropper_layer(x), y))\n",
    "normalized_ds_train = cropped_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "cropped_ds = val_ds.map(lambda x, y: (cropper_layer(x), y))\n",
    "normalized_ds_valid = cropped_ds.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = normalized_ds_train.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = normalized_ds_valid.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input((32, 32, 3)),\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu'), # 13 spectral bands\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(10) # 10 different classes in the EuroSAT dataset\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_accuracy', patience=10, verbose=0, mode='auto')\n",
    "mcp_save = ModelCheckpoint(\"ground_finder.keras\", save_best_only=True, monitor='val_accuracy', mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "675/675 [==============================] - 4s 5ms/step - loss: 1.4673 - accuracy: 0.4287 - val_loss: 1.1593 - val_accuracy: 0.5752\n",
      "Epoch 2/100\n",
      "675/675 [==============================] - 3s 4ms/step - loss: 1.0761 - accuracy: 0.6075 - val_loss: 1.2589 - val_accuracy: 0.5198\n",
      "Epoch 3/100\n",
      "675/675 [==============================] - 3s 4ms/step - loss: 0.9278 - accuracy: 0.6684 - val_loss: 1.2301 - val_accuracy: 0.5422\n",
      "Epoch 4/100\n",
      "675/675 [==============================] - 3s 4ms/step - loss: 0.8332 - accuracy: 0.6986 - val_loss: 1.0934 - val_accuracy: 0.6050\n",
      "Epoch 5/100\n",
      "675/675 [==============================] - 3s 4ms/step - loss: 0.7740 - accuracy: 0.7242 - val_loss: 0.9444 - val_accuracy: 0.6561\n",
      "Epoch 6/100\n",
      "675/675 [==============================] - 3s 4ms/step - loss: 0.7317 - accuracy: 0.7410 - val_loss: 0.8879 - val_accuracy: 0.6794\n",
      "Epoch 7/100\n",
      "675/675 [==============================] - 3s 4ms/step - loss: 0.6957 - accuracy: 0.7531 - val_loss: 0.9439 - val_accuracy: 0.6559\n",
      "Epoch 8/100\n",
      "675/675 [==============================] - 3s 4ms/step - loss: 0.6661 - accuracy: 0.7625 - val_loss: 0.7972 - val_accuracy: 0.7156\n",
      "Epoch 9/100\n",
      "675/675 [==============================] - 3s 4ms/step - loss: 0.6440 - accuracy: 0.7727 - val_loss: 0.7138 - val_accuracy: 0.7493\n",
      "Epoch 10/100\n",
      "675/675 [==============================] - 3s 4ms/step - loss: 0.6296 - accuracy: 0.7781 - val_loss: 0.7503 - val_accuracy: 0.7317\n",
      "Epoch 11/100\n",
      "675/675 [==============================] - 3s 4ms/step - loss: 0.6047 - accuracy: 0.7859 - val_loss: 0.6708 - val_accuracy: 0.7607\n",
      "Epoch 12/100\n",
      "675/675 [==============================] - 3s 4ms/step - loss: 0.5868 - accuracy: 0.7937 - val_loss: 0.6664 - val_accuracy: 0.7626\n",
      "Epoch 13/100\n",
      "675/675 [==============================] - 3s 5ms/step - loss: 0.5744 - accuracy: 0.7971 - val_loss: 0.6668 - val_accuracy: 0.7656\n",
      "Epoch 14/100\n",
      "675/675 [==============================] - 3s 5ms/step - loss: 0.5563 - accuracy: 0.8054 - val_loss: 0.6666 - val_accuracy: 0.7596\n",
      "Epoch 15/100\n",
      "675/675 [==============================] - 3s 4ms/step - loss: 0.5385 - accuracy: 0.8131 - val_loss: 0.6651 - val_accuracy: 0.7615\n",
      "Epoch 16/100\n",
      "675/675 [==============================] - 3s 4ms/step - loss: 0.5217 - accuracy: 0.8154 - val_loss: 0.6751 - val_accuracy: 0.7507\n",
      "Epoch 17/100\n",
      "675/675 [==============================] - 3s 4ms/step - loss: 0.5126 - accuracy: 0.8179 - val_loss: 0.6741 - val_accuracy: 0.7609\n",
      "Epoch 18/100\n",
      "675/675 [==============================] - 3s 4ms/step - loss: 0.5093 - accuracy: 0.8199 - val_loss: 0.7605 - val_accuracy: 0.7348\n",
      "Epoch 19/100\n",
      "675/675 [==============================] - 3s 4ms/step - loss: 0.4844 - accuracy: 0.8311 - val_loss: 0.7226 - val_accuracy: 0.7452\n",
      "Epoch 20/100\n",
      "675/675 [==============================] - 3s 4ms/step - loss: 0.4701 - accuracy: 0.8366 - val_loss: 0.6459 - val_accuracy: 0.7730\n",
      "Epoch 21/100\n",
      "675/675 [==============================] - 3s 4ms/step - loss: 0.4646 - accuracy: 0.8365 - val_loss: 0.7968 - val_accuracy: 0.7206\n",
      "Epoch 22/100\n",
      "675/675 [==============================] - 3s 4ms/step - loss: 0.4517 - accuracy: 0.8390 - val_loss: 0.6437 - val_accuracy: 0.7735\n",
      "Epoch 23/100\n",
      "675/675 [==============================] - 3s 4ms/step - loss: 0.4419 - accuracy: 0.8436 - val_loss: 0.6434 - val_accuracy: 0.7754\n",
      "Epoch 24/100\n",
      "675/675 [==============================] - 3s 4ms/step - loss: 0.4415 - accuracy: 0.8444 - val_loss: 0.5685 - val_accuracy: 0.8048\n",
      "Epoch 25/100\n",
      "675/675 [==============================] - 3s 4ms/step - loss: 0.4240 - accuracy: 0.8494 - val_loss: 0.5804 - val_accuracy: 0.8033\n",
      "Epoch 26/100\n",
      "675/675 [==============================] - 3s 4ms/step - loss: 0.4079 - accuracy: 0.8550 - val_loss: 0.5708 - val_accuracy: 0.8067\n",
      "Epoch 27/100\n",
      "675/675 [==============================] - 3s 4ms/step - loss: 0.4103 - accuracy: 0.8542 - val_loss: 0.5700 - val_accuracy: 0.8126\n",
      "Epoch 28/100\n",
      "675/675 [==============================] - 3s 4ms/step - loss: 0.3982 - accuracy: 0.8591 - val_loss: 0.5917 - val_accuracy: 0.8133\n",
      "Epoch 29/100\n",
      "675/675 [==============================] - 3s 4ms/step - loss: 0.3820 - accuracy: 0.8648 - val_loss: 0.5917 - val_accuracy: 0.8026\n",
      "Epoch 30/100\n",
      "675/675 [==============================] - 3s 4ms/step - loss: 0.3759 - accuracy: 0.8676 - val_loss: 0.5455 - val_accuracy: 0.8241\n",
      "Epoch 31/100\n",
      "675/675 [==============================] - 3s 4ms/step - loss: 0.3647 - accuracy: 0.8711 - val_loss: 0.5665 - val_accuracy: 0.8194\n",
      "Epoch 32/100\n",
      "675/675 [==============================] - 3s 4ms/step - loss: 0.3536 - accuracy: 0.8742 - val_loss: 0.5541 - val_accuracy: 0.8204\n",
      "Epoch 33/100\n",
      "675/675 [==============================] - 3s 4ms/step - loss: 0.3604 - accuracy: 0.8728 - val_loss: 0.5649 - val_accuracy: 0.8193\n",
      "Epoch 34/100\n",
      "675/675 [==============================] - 3s 4ms/step - loss: 0.3380 - accuracy: 0.8781 - val_loss: 0.6689 - val_accuracy: 0.7778\n",
      "Epoch 35/100\n",
      "675/675 [==============================] - 3s 5ms/step - loss: 0.3384 - accuracy: 0.8807 - val_loss: 0.5717 - val_accuracy: 0.8213\n",
      "Epoch 36/100\n",
      "675/675 [==============================] - 3s 4ms/step - loss: 0.3282 - accuracy: 0.8851 - val_loss: 0.5804 - val_accuracy: 0.8206\n",
      "Epoch 37/100\n",
      "675/675 [==============================] - 3s 4ms/step - loss: 0.3236 - accuracy: 0.8858 - val_loss: 0.6448 - val_accuracy: 0.7974\n",
      "Epoch 38/100\n",
      "675/675 [==============================] - 3s 5ms/step - loss: 0.3114 - accuracy: 0.8907 - val_loss: 0.6285 - val_accuracy: 0.8124\n",
      "Epoch 39/100\n",
      "675/675 [==============================] - 3s 5ms/step - loss: 0.3145 - accuracy: 0.8889 - val_loss: 0.6661 - val_accuracy: 0.7869\n",
      "Epoch 40/100\n",
      "675/675 [==============================] - 3s 4ms/step - loss: 0.2984 - accuracy: 0.8928 - val_loss: 0.6379 - val_accuracy: 0.8067\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=100,\n",
    "callbacks=[earlyStopping, mcp_save]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
